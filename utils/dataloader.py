import os
from PIL import Image
import torch.utils.data as data
import albumentations as A
from albumentations.pytorch import ToTensorV2
import torchvision.transforms as transforms
import torch.utils.data as data
import albumentations as A
import numpy as np
import torch

class CODataset(data.Dataset):
    def __init__(self, image_root, gt_root, trainsize, augmentations=True):
        self.trainsize = trainsize
        self.augmentations = augmentations

        # Contar im√°genes originales
        original_images = [f for f in os.listdir(image_root) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
        original_gts = [f for f in os.listdir(gt_root) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]

        print(f"üìä ESTAD√çSTICAS DEL DATASET:")
        print(f"   ‚Ä¢ Im√°genes originales encontradas: {len(original_images)}")
        print(f"   ‚Ä¢ Ground truths originales encontrados: {len(original_gts)}")

        self.images = sorted([os.path.join(image_root, f) for f in original_images])
        self.gts = sorted([os.path.join(gt_root, f) for f in original_gts])

        # Preprocesar y redimensionar UNA SOLA VEZ
        self.preprocess_and_resize()
        self.size = len(self.processed_data)

        print(f"   ‚Ä¢ Pares procesados exitosamente: {self.size}")

        # Mostrar informaci√≥n sobre augmentaciones
        if self.augmentations:
            print(f"   ‚Ä¢ üîÑ AUGMENTACIONES ACTIVADAS:")
            print(f"     - Cada imagen se transforma aleatoriamente en cada √©poca")
            print(f"     - Variaciones efectivas por √©poca: {self.size} √ó m√∫ltiples transformaciones")
            print(f"     - HorizontalFlip, VerticalFlip, Rotaciones, Brillo, Contraste, etc.")
        else:
            print(f"   ‚Ä¢ ‚ùå AUGMENTACIONES DESACTIVADAS:")
            print(f"     - Solo resize y normalizaci√≥n")
            print(f"     - N√∫mero fijo de im√°genes: {self.size}")

        # Configurar transformaciones
        self.transform = self.get_transforms()

    def preprocess_and_resize(self):
        """
        Preprocesa y redimensiona las im√°genes UNA SOLA VEZ al inicializar
        """
        print(f"\nüîß PREPROCESANDO IM√ÅGENES (una sola vez):")

        self.processed_data = []
        resized_count = 0
        error_count = 0

        for img_path, gt_path in zip(self.images, self.gts):
            try:
                # Cargar imagen y m√°scara
                image = Image.open(img_path).convert('RGB')
                gt = Image.open(gt_path).convert('L')

                # Verificar si necesitan resize
                if image.size != gt.size:
                    resized_count += 1
                    target_size = image.size  # Usar tama√±o de la imagen como referencia
                    print(f"   üìè Redimensionando {os.path.basename(gt_path)}: {gt.size} ‚Üí {target_size}")

                    # Resize de la m√°scara usando interpolaci√≥n bic√∫bica
                    gt = gt.resize(target_size, Image.BICUBIC)

                # Convertir a numpy arrays y guardar
                image_np = np.array(image)
                gt_np = np.array(gt)

                self.processed_data.append((image_np, gt_np))

            except Exception as e:
                error_count += 1
                print(f"   ‚ùå Error procesando {os.path.basename(img_path)}: {str(e)}")

        print(f"\nüìà RESUMEN DEL PREPROCESAMIENTO:")
        print(f"   ‚Ä¢ Pares procesados: {len(self.processed_data)}")
        print(f"   ‚Ä¢ M√°scaras redimensionadas: {resized_count}")
        print(f"   ‚Ä¢ Errores encontrados: {error_count}")
        print(f"   ‚Ä¢ ‚úÖ Todas las im√°genes est√°n listas para augmentaci√≥n")

    def get_transforms(self):
        if self.augmentations:
            print('\nüé® CONFIGURANDO AUGMENTACIONES AVANZADAS:')
            transform = A.Compose([
                A.Resize(self.trainsize, self.trainsize),
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.5),
                A.RandomRotate90(p=0.5),
                A.ShiftScaleRotate(
                    shift_limit=0.1, 
                    scale_limit=0.1, 
                    rotate_limit=45, 
                    p=0.5, 
                    border_mode=0
                ),
                A.RandomBrightnessContrast(
                    brightness_limit=0.2,
                    contrast_limit=0.2,
                    p=0.5
                ),
                A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),
                A.HueSaturationValue(
                    hue_shift_limit=20,
                    sat_shift_limit=30,
                    val_shift_limit=20,
                    p=0.3
                ),
                A.Normalize(
                    mean=(0.485, 0.456, 0.406),
                    std=(0.229, 0.224, 0.225)
                ),
                ToTensorV2()
            ])

            print('   ‚úÖ Augmentaciones configuradas:')
            print('      - Geom√©tricas: Flip H/V (50%), Rotaci√≥n 90¬∞ (50%), ShiftScaleRotate (50%)')
            print('      - Fotom√©tricas: Brillo/Contraste (50%), Ruido Gaussiano (30%)')
            print('      - Color: HSV (30%)')
            print('      - Normalizaci√≥n ImageNet + ToTensor')

            return transform
        else:
            print('\n‚û°Ô∏è  CONFIGURANDO TRANSFORMACIONES B√ÅSICAS:')
            transform = A.Compose([
                A.Resize(self.trainsize, self.trainsize),
                A.Normalize(
                    mean=(0.485, 0.456, 0.406),
                    std=(0.229, 0.224, 0.225)
                ),
                ToTensorV2()
            ])
            print('   ‚úÖ Solo resize + normalizaci√≥n configurados')
            return transform

    def __getitem__(self, index):
        # Obtener datos preprocesados (ya redimensionados una vez)
        image_np, gt_np = self.processed_data[index]

        # Aplicar augmentaciones (si est√°n activadas)
        augmented = self.transform(image=image_np, mask=gt_np)
        image = augmented['image']
        gt = augmented['mask'].unsqueeze(0).float() / 255.0

        return image, gt

    def __len__(self):
        return self.size

def get_loader(image_root, gt_root, batchsize, trainsize, shuffle=True, num_workers=4, pin_memory=True, augmentation=True):
    print(f"\nüöÄ CREANDO DATALOADER:")
    print(f"   ‚Ä¢ Directorio de im√°genes: {image_root}")
    print(f"   ‚Ä¢ Directorio de ground truths: {gt_root}")
    print(f"   ‚Ä¢ Tama√±o de entrenamiento: {trainsize}x{trainsize}")
    print(f"   ‚Ä¢ Batch size: {batchsize}")
    print(f"   ‚Ä¢ Augmentaciones: {'‚úÖ Activadas' if augmentation else '‚ùå Desactivadas'}")

    dataset = CODataset(image_root, gt_root, trainsize, augmentation)

    # Calcular informaci√≥n adicional del entrenamiento
    total_batches = len(dataset) // batchsize
    remaining_samples = len(dataset) % batchsize

    print(f"\nüìà INFORMACI√ìN DE ENTRENAMIENTO:")
    print(f"   ‚Ä¢ Total de im√°genes para entrenamiento: {len(dataset)}")
    print(f"   ‚Ä¢ Batches por √©poca: {total_batches}")
    if remaining_samples > 0:
        print(f"   ‚Ä¢ Muestras en el √∫ltimo batch: {remaining_samples}")

    if augmentation:
        print(f"   ‚Ä¢ üé≤ Variaciones por √©poca: INFINITAS (transformaciones aleatorias)")
        print(f"   ‚Ä¢ üîÑ Cada √©poca ver√° versiones diferentes de las mismas im√°genes")
    else:
        print(f"   ‚Ä¢ üìä Muestras fijas por √©poca: {len(dataset)}")

    data_loader = data.DataLoader(
        dataset=dataset,
        batch_size=batchsize,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=pin_memory
    )
    return data_loader

class test_dataset:
    def __init__(self, image_root, gt_root, testsize):
        self.testsize = testsize
        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg') or f.endswith('.png') or f.endswith('.jpeg') or f.endswith('.JPG')]
        self.gts = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.tif') or f.endswith('.png') or f.endswith('.jpg') or f.endswith('.jpeg') or f.endswith('.JPG')]

        self.images = sorted(self.images)
        self.gts = sorted(self.gts)

        print(f"\nüß™ DATASET DE PRUEBA:")
        print(f"   ‚Ä¢ Im√°genes de prueba: {len(self.images)}")
        print(f"   ‚Ä¢ Ground truths de prueba: {len(self.gts)}")
        print(f"   ‚Ä¢ ‚ö†Ô∏è  NOTA: Las im√°genes de prueba se redimensionan en cada load_data()")

        self.transform = transforms.Compose([
            transforms.Resize((self.testsize, self.testsize)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        self.gt_transform = transforms.ToTensor()
        self.size = len(self.images)
        self.index = 0

    def load_data(self):
        image = self.rgb_loader(self.images[self.index])
        gt = self.binary_loader(self.gts[self.index])

        # Verificar y ajustar tama√±os si es necesario (solo para test)
        if image.size != gt.size:
            gt = gt.resize(image.size, Image.BICUBIC)

        image = self.transform(image).unsqueeze(0)

        name = self.images[self.index].split('/')[-1]
        if name.endswith('.jpg'):
            name = name.split('.jpg')[0] + '.png'
        self.index += 1
        return image, gt, name

    def rgb_loader(self, path):
        with open(path, 'rb') as f:
            img = Image.open(f)
            return img.convert('RGB')

    def binary_loader(self, path):
        with open(path, 'rb') as f:
            img = Image.open(f)
            return img.convert('L')

    def __len__(self):
        return self.size

# Funci√≥n para mostrar resumen completo del dataset
def show_dataset_summary(train_loader, test_dataset=None):
    """
    Muestra un resumen completo del dataset con informaci√≥n de augmentaciones
    """
    print(f"\n" + "="*70)
    print(f"üìã RESUMEN COMPLETO DEL DATASET")
    print(f"="*70)

    # Informaci√≥n del dataset de entrenamiento
    train_dataset = train_loader.dataset
    print(f"üèãÔ∏è  ENTRENAMIENTO:")
    print(f"   ‚Ä¢ Im√°genes base: {len(train_dataset)}")
    print(f"   ‚Ä¢ Batch size: {train_loader.batch_size}")
    print(f"   ‚Ä¢ Batches por √©poca: {len(train_loader)}")
    print(f"   ‚Ä¢ Preprocesamiento: ‚úÖ Una sola vez al inicializar")

    if train_dataset.augmentations:
        print(f"   ‚Ä¢ Augmentaciones: ‚úÖ ACTIVADAS")
        print(f"     - Cada imagen se transforma aleatoriamente")
        print(f"     - Variaciones por √©poca: INFINITAS")
        print(f"     - Diversidad: Muy alta")
    else:
        print(f"   ‚Ä¢ Augmentaciones: ‚ùå DESACTIVADAS")
        print(f"     - Im√°genes fijas por √©poca: {len(train_dataset)}")
        print(f"     - Diversidad: Limitada")

    if test_dataset:
        print(f"\nüß™ PRUEBA:")
        print(f"   ‚Ä¢ Im√°genes de prueba: {len(test_dataset)}")
        print(f"   ‚Ä¢ Augmentaciones: ‚ùå Desactivadas (solo resize)")

    print(f"\nüíæ CONFIGURACI√ìN:")
    print(f"   ‚Ä¢ Tama√±o de imagen: {train_dataset.trainsize}x{train_dataset.trainsize}")
    print(f"   ‚Ä¢ Shuffle: {'‚úÖ' if train_loader.sampler is None else '‚ùå'}")
    print(f"   ‚Ä¢ Num workers: {train_loader.num_workers}")
    print(f"   ‚Ä¢ Pin memory: {'‚úÖ' if train_loader.pin_memory else '‚ùå'}")
    print(f"="*70)

# Funci√≥n para demostrar el efecto de las augmentaciones
def demonstrate_augmentations(dataset, num_samples=3):
    """
    Demuestra c√≥mo las augmentaciones crean diferentes versiones de la misma imagen
    """
    if not dataset.augmentations:
        print("‚ùå Las augmentaciones est√°n desactivadas")
        return

    print(f"\nüé® DEMOSTRACI√ìN DE AUGMENTACIONES:")
    print(f"Mostrando {num_samples} transformaciones de la primera imagen...")

    for i in range(num_samples):
        image, gt = dataset[0]  # Siempre la misma imagen base
        print(f"   Muestra {i+1}: Tensor shape {image.shape}, GT shape {gt.shape}")
        print(f"   - Valores √∫nicos en imagen: {len(torch.unique(image))}")
        print(f"   - Min/Max imagen: {image.min():.3f}/{image.max():.3f}")

    print("‚úÖ Cada llamada produce una transformaci√≥n diferente!")

def verify_dataset_integrity(image_root, gt_root):
    """
    Verifica la integridad del dataset antes del preprocesamiento
    """
    print(f"\nüîç VERIFICANDO INTEGRIDAD DEL DATASET...")

    images = sorted([f for f in os.listdir(image_root) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])
    gts = sorted([f for f in os.listdir(gt_root) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])

    size_stats = {}
    mismatches = 0

    for img_name, gt_name in zip(images, gts):
        try:
            img = Image.open(os.path.join(image_root, img_name))
            gt = Image.open(os.path.join(gt_root, gt_name))

            img_size = img.size
            gt_size = gt.size

            if img_size != gt_size:
                mismatches += 1

            # Estad√≠sticas de tama√±os
            if img_size not in size_stats:
                size_stats[img_size] = 0
            size_stats[img_size] += 1

        except Exception as e:
            print(f"   ‚ùå Error con {img_name}: {e}")

    print(f"\nüìä ESTAD√çSTICAS DE TAMA√ëOS:")
    for size, count in sorted(size_stats.items(), key=lambda x: x[1], reverse=True):
        print(f"   ‚Ä¢ {size}: {count} im√°genes")

    print(f"\nüìà RESUMEN:")
    print(f"   ‚Ä¢ Total de pares: {len(images)}")
    print(f"   ‚Ä¢ Pares con tama√±os diferentes: {mismatches}")
    print(f"   ‚Ä¢ üîß Se redimensionar√°n {mismatches} m√°scaras UNA SOLA VEZ")

    return len(images), mismatches
