import os
from PIL import Image
import torch.utils.data as data
import albumentations as A
from albumentations.pytorch import ToTensorV2
import torchvision.transforms as transforms
import torch.utils.data as data
import albumentations as A
import numpy as np
import torch

class CODataset(data.Dataset):
    def __init__(self, image_root, gt_root, trainsize, augmentations=True):
        self.trainsize = trainsize
        self.augmentations = augmentations

        # Contar im√°genes originales
        original_images = [f for f in os.listdir(image_root) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
        original_gts = [f for f in os.listdir(gt_root) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]

        print(f"üìä ESTAD√çSTICAS DEL DATASET:")
        print(f"   ‚Ä¢ Im√°genes originales encontradas: {len(original_images)}")
        print(f"   ‚Ä¢ Ground truths originales encontrados: {len(original_gts)}")

        self.images = sorted([os.path.join(image_root, f) for f in original_images])
        self.gts = sorted([os.path.join(gt_root, f) for f in original_gts])

        # Procesar archivos con resize autom√°tico
        self.process_files()
        self.size = len(self.images)

        print(f"   ‚Ä¢ Im√°genes procesadas exitosamente: {self.size}")

        # Mostrar informaci√≥n sobre augmentaciones
        if self.augmentations:
            print(f"   ‚Ä¢ Augmentaciones ACTIVADAS - cada imagen se puede transformar de m√∫ltiples formas")
            print(f"   ‚Ä¢ N√∫mero efectivo de variaciones por √©poca: {self.size} √ó (transformaciones aleatorias)")
        else:
            print(f"   ‚Ä¢ Augmentaciones DESACTIVADAS - solo resize y normalizaci√≥n")
            print(f"   ‚Ä¢ N√∫mero de im√°genes para entrenamiento: {self.size}")

        self.transform = self.get_transforms()

    def get_transforms(self):
        if self.augmentations:
            print('üîÑ Usando Albumentations avanzadas para augmentaci√≥n:')
            print('   - HorizontalFlip (50%), VerticalFlip (50%), RandomRotate90 (50%)')
            print('   - ShiftScaleRotate (50%), RandomBrightnessContrast (50%)')
            print('   - GaussNoise (30%), HueSaturationValue (30%)')
            return A.Compose([
                A.Resize(self.trainsize, self.trainsize),
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.5),
                A.RandomRotate90(p=0.5),
                A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=45, p=0.5, border_mode=0),
                A.RandomBrightnessContrast(p=0.5),
                A.GaussNoise(p=0.3),
                A.HueSaturationValue(p=0.3),
                A.Normalize(mean=(0.485, 0.456, 0.406),
                            std=(0.229, 0.224, 0.225)),
                ToTensorV2()
            ],)
        else:
            print('‚û°Ô∏è  Sin augmentaci√≥n, solo resize y normalizaci√≥n')
            return A.Compose([
                A.Resize(self.trainsize, self.trainsize),
                A.Normalize(mean=(0.485, 0.456, 0.406),
                            std=(0.229, 0.224, 0.225)),
                ToTensorV2()
            ],)  

    def __getitem__(self, index):
        # Cargar imagen y m√°scara
        image_path = self.images[index]
        gt_path = self.gts[index]

        try:
            # Cargar imagen
            image = Image.open(image_path).convert('RGB')
            gt = Image.open(gt_path).convert('L')

            # Verificar si necesitan resize para coincidir
            if image.size != gt.size:
                # Usar el tama√±o de la imagen como referencia
                target_size = image.size
                print(f"   üîß Redimensionando m√°scara de {gt.size} a {target_size} para {os.path.basename(image_path)}")

                # Resize de la m√°scara usando interpolaci√≥n bic√∫bica
                gt = gt.resize(target_size, Image.BICUBIC)

            # Convertir a numpy para Albumentations
            image = np.array(image)
            gt = np.array(gt)

            # Aplicar transformaciones
            augmented = self.transform(image=image, mask=gt)
            image = augmented['image']
            gt = augmented['mask'].unsqueeze(0).float() / 255.0

            return image, gt

        except Exception as e:
            print(f"   ‚ùå Error procesando {os.path.basename(image_path)}: {str(e)}")
            # En caso de error, devolver una imagen en blanco del tama√±o correcto
            dummy_image = torch.zeros(3, self.trainsize, self.trainsize)
            dummy_gt = torch.zeros(1, self.trainsize, self.trainsize)
            return dummy_image, dummy_gt

    def process_files(self):
        """
        Procesa los archivos verificando que existan pares imagen-m√°scara
        En lugar de filtrar, redimensiona autom√°ticamente
        """
        assert len(self.images) == len(self.gts), f"‚ùå Error: {len(self.images)} im√°genes vs {len(self.gts)} ground truths"

        valid_images, valid_gts = [], []
        size_mismatches = 0
        errors = 0

        print(f"\nüîç PROCESANDO ARCHIVOS:")

        for img_path, gt_path in zip(self.images, self.gts):
            try:
                # Verificar que ambos archivos existan y se puedan abrir
                img = Image.open(img_path)
                gt = Image.open(gt_path)

                # Contar desajustes de tama√±o (pero no filtrar)
                if img.size != gt.size:
                    size_mismatches += 1
                    print(f"   üìè Tama√±os diferentes: {os.path.basename(img_path)} {img.size} vs {os.path.basename(gt_path)} {gt.size}")

                # Agregar a la lista v√°lida (se redimensionar√° en __getitem__)
                valid_images.append(img_path)
                valid_gts.append(gt_path)

            except Exception as e:
                errors += 1
                print(f"   ‚ùå Error al abrir: {os.path.basename(img_path)} - {str(e)}")

        print(f"\nüìà RESUMEN DEL PROCESAMIENTO:")
        print(f"   ‚Ä¢ Pares v√°lidos: {len(valid_images)}")
        print(f"   ‚Ä¢ Pares con tama√±os diferentes (se redimensionar√°n): {size_mismatches}")
        print(f"   ‚Ä¢ Archivos con errores (excluidos): {errors}")

        if size_mismatches > 0:
            print(f"   üîß Las m√°scaras se redimensionar√°n autom√°ticamente usando interpolaci√≥n bic√∫bica")

        self.images, self.gts = valid_images, valid_gts

    def __len__(self):
        return self.size

def get_loader(image_root, gt_root, batchsize, trainsize, shuffle=True, num_workers=4, pin_memory=True, augmentation=True):
    print(f"\nüöÄ CREANDO DATALOADER:")
    print(f"   ‚Ä¢ Directorio de im√°genes: {image_root}")
    print(f"   ‚Ä¢ Directorio de ground truths: {gt_root}")
    print(f"   ‚Ä¢ Tama√±o de entrenamiento: {trainsize}x{trainsize}")
    print(f"   ‚Ä¢ Batch size: {batchsize}")

    dataset = CODataset(image_root, gt_root, trainsize, augmentation)

    # Calcular informaci√≥n adicional del entrenamiento
    total_batches = len(dataset) // batchsize
    remaining_samples = len(dataset) % batchsize

    print(f"\nüìà INFORMACI√ìN DE ENTRENAMIENTO:")
    print(f"   ‚Ä¢ Total de im√°genes para entrenamiento: {len(dataset)}")
    print(f"   ‚Ä¢ Batches por √©poca: {total_batches}")
    if remaining_samples > 0:
        print(f"   ‚Ä¢ Muestras en el √∫ltimo batch: {remaining_samples}")
    print(f"   ‚Ä¢ Muestras procesadas por √©poca: {len(dataset)}")

    data_loader = data.DataLoader(dataset=dataset,
                                  batch_size=batchsize,
                                  shuffle=shuffle,
                                  num_workers=num_workers,
                                  pin_memory=pin_memory)
    return data_loader

class test_dataset:
    def __init__(self, image_root, gt_root, testsize):
        self.testsize = testsize
        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg') or f.endswith('.png') or f.endswith('.jpeg') or f.endswith('.JPG')]
        self.gts = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.tif') or f.endswith('.png') or f.endswith('.jpg') or f.endswith('.jpeg') or f.endswith('.JPG')]

        self.images = sorted(self.images)
        self.gts = sorted(self.gts)

        print(f"\nüß™ DATASET DE PRUEBA:")
        print(f"   ‚Ä¢ Im√°genes de prueba: {len(self.images)}")
        print(f"   ‚Ä¢ Ground truths de prueba: {len(self.gts)}")

        self.transform = transforms.Compose([
            transforms.Resize((self.testsize, self.testsize)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406],
                                 [0.229, 0.224, 0.225])])
        self.gt_transform = transforms.ToTensor()
        self.size = len(self.images)
        self.index = 0

    def load_data(self):
        image = self.rgb_loader(self.images[self.index])
        gt = self.binary_loader(self.gts[self.index])

        # Verificar y ajustar tama√±os si es necesario
        if image.size != gt.size:
            print(f"   üîß Redimensionando GT de {gt.size} a {image.size} para test")
            gt = gt.resize(image.size, Image.BICUBIC)

        image = self.transform(image).unsqueeze(0)

        name = self.images[self.index].split('/')[-1]
        if name.endswith('.jpg'):
            name = name.split('.jpg')[0] + '.png'
        self.index += 1
        return image, gt, name

    def rgb_loader(self, path):
        with open(path, 'rb') as f:
            img = Image.open(f)
            return img.convert('RGB')

    def binary_loader(self, path):
        with open(path, 'rb') as f:
            img = Image.open(f)
            return img.convert('L')

    def __len__(self):
        return self.size

class My_test_dataset:
    def __init__(self, image_root, gt_root, testsize):
        self.testsize = testsize
        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg') or f.endswith('.png') or f.endswith('.jpeg') or f.endswith('.JPG')]
        self.gts = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.tif') or f.endswith('.jpg') or f.endswith('.png') or f.endswith('.jpeg') or f.endswith('.JPG')]

        self.images = sorted(self.images)
        self.gts = sorted(self.gts)

        print(f"\nüîç MI DATASET DE PRUEBA:")
        print(f"   ‚Ä¢ Im√°genes de prueba: {len(self.images)}")
        print(f"   ‚Ä¢ Ground truths de prueba: {len(self.gts)}")

        self.transform = transforms.Compose([
            transforms.Resize((self.testsize, self.testsize)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
        self.gt_transform = transforms.ToTensor()
        self.size = len(self.images)
        self.index = 0

    def load_data(self):
        image = self.rgb_loader(self.images[self.index])
        gt = self.binary_loader(self.gts[self.index])

        # Verificar y ajustar tama√±os si es necesario
        if image.size != gt.size:
            print(f"   üîß Redimensionando GT de {gt.size} a {image.size} para mi test")
            gt = gt.resize(image.size, Image.BICUBIC)

        image = self.transform(image).unsqueeze(0)

        name = self.images[self.index].split('/')[-1]
        if name.endswith('.jpg'):
            name = name.split('.jpg')[0] + '.png'
        self.index += 1
        return image, gt, name

    def rgb_loader(self, path):
        with open(path, 'rb') as f:
            img = Image.open(f)
            return img.convert('RGB')

    def binary_loader(self, path):
        with open(path, 'rb') as f:
            img = Image.open(f)
            return img.convert('L')

    def __len__(self):
        return self.size

# Funci√≥n adicional para mostrar resumen completo del dataset
def show_dataset_summary(train_loader, test_dataset=None):
    """
    Muestra un resumen completo del dataset
    """
    print(f"\n" + "="*60)
    print(f"üìã RESUMEN COMPLETO DEL DATASET")
    print(f"="*60)

    # Informaci√≥n del dataset de entrenamiento
    train_dataset = train_loader.dataset
    print(f"üèãÔ∏è  ENTRENAMIENTO:")
    print(f"   ‚Ä¢ Im√°genes totales: {len(train_dataset)}")
    print(f"   ‚Ä¢ Batch size: {train_loader.batch_size}")
    print(f"   ‚Ä¢ Batches por √©poca: {len(train_loader)}")
    print(f"   ‚Ä¢ Augmentaciones: {'‚úÖ Activadas' if train_dataset.augmentations else '‚ùå Desactivadas'}")
    print(f"   ‚Ä¢ Resize autom√°tico: ‚úÖ Activado (interpolaci√≥n bic√∫bica)")

    if test_dataset:
        print(f"\nüß™ PRUEBA:")
        print(f"   ‚Ä¢ Im√°genes de prueba: {len(test_dataset)}")

    print(f"\nüíæ CONFIGURACI√ìN:")
    print(f"   ‚Ä¢ Tama√±o de imagen: {train_dataset.trainsize}x{train_dataset.trainsize}")
    print(f"   ‚Ä¢ Shuffle: {'‚úÖ' if train_loader.sampler is None else '‚ùå'}")
    print(f"   ‚Ä¢ Num workers: {train_loader.num_workers}")
    print(f"   ‚Ä¢ Pin memory: {'‚úÖ' if train_loader.pin_memory else '‚ùå'}")
    print(f"="*60)

# Funci√≥n para verificar la integridad del dataset
def verify_dataset_integrity(image_root, gt_root):
    """
    Verifica la integridad del dataset y muestra estad√≠sticas de tama√±os
    """
    print(f"\nüîç VERIFICANDO INTEGRIDAD DEL DATASET...")

    images = sorted([f for f in os.listdir(image_root) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])
    gts = sorted([f for f in os.listdir(gt_root) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])

    size_stats = {}
    mismatches = 0

    for img_name, gt_name in zip(images, gts):
        try:
            img = Image.open(os.path.join(image_root, img_name))
            gt = Image.open(os.path.join(gt_root, gt_name))

            img_size = img.size
            gt_size = gt.size

            if img_size != gt_size:
                mismatches += 1
                print(f"   üìè {img_name}: imagen {img_size} vs m√°scara {gt_size}")

            # Estad√≠sticas de tama√±os
            if img_size not in size_stats:
                size_stats[img_size] = 0
            size_stats[img_size] += 1

        except Exception as e:
            print(f"   ‚ùå Error con {img_name}: {e}")

    print(f"\nüìä ESTAD√çSTICAS DE TAMA√ëOS:")
    for size, count in sorted(size_stats.items(), key=lambda x: x[1], reverse=True):
        print(f"   ‚Ä¢ {size}: {count} im√°genes")

    print(f"\nüìà RESUMEN:")
    print(f"   ‚Ä¢ Total de pares: {len(images)}")
    print(f"   ‚Ä¢ Pares con tama√±os diferentes: {mismatches}")
    print(f"   ‚Ä¢ Pares que necesitan resize: {mismatches}")

    return len(images), mismatches
