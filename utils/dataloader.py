import os
from PIL import Image
import torch.utils.data as data
import albumentations as A
from albumentations.pytorch import ToTensorV2
import torchvision.transforms as transforms
import torch.utils.data as data
import albumentations as A
import numpy as np
import torch

class CODataset(data.Dataset):
    def __init__(self, image_root, gt_root, trainsize, augmentations=True):
        self.trainsize = trainsize
        self.augmentations = augmentations

        # Contar imÃ¡genes originales
        original_images = [f for f in os.listdir(image_root) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
        original_gts = [f for f in os.listdir(gt_root) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]

        print(f"ğŸ“Š ESTADÃSTICAS DEL DATASET:")
        print(f"   â€¢ ImÃ¡genes originales encontradas: {len(original_images)}")
        print(f"   â€¢ Ground truths originales encontrados: {len(original_gts)}")

        self.images = sorted([os.path.join(image_root, f) for f in original_images])
        self.gts = sorted([os.path.join(gt_root, f) for f in original_gts])

        # Preprocesar y redimensionar UNA SOLA VEZ
        self.preprocess_and_resize()
        self.size = len(self.processed_data)

        print(f"   â€¢ Pares procesados exitosamente: {self.size}")

        # Mostrar informaciÃ³n sobre augmentaciones
        if self.augmentations:
            print(f"   â€¢ ğŸ”„ AUGMENTACIONES ACTIVADAS:")
            print(f"     - Cada imagen se transforma aleatoriamente en cada Ã©poca")
            print(f"     - Variaciones efectivas por Ã©poca: {self.size} Ã— mÃºltiples transformaciones")
            print(f"     - HorizontalFlip, VerticalFlip, Rotaciones, Brillo, Contraste, etc.")
        else:
            print(f"   â€¢ âŒ AUGMENTACIONES DESACTIVADAS:")
            print(f"     - Solo resize y normalizaciÃ³n")
            print(f"     - NÃºmero fijo de imÃ¡genes: {self.size}")

        # Configurar transformaciones
        self.transform = self.get_transforms()

    def preprocess_and_resize(self):
        """
        Preprocesa y redimensiona las imÃ¡genes UNA SOLA VEZ al inicializar
        """
        print(f"\nğŸ”§ PREPROCESANDO IMÃGENES (una sola vez):")

        self.processed_data = []
        resized_count = 0
        error_count = 0

        for img_path, gt_path in zip(self.images, self.gts):
            try:
                # Cargar imagen y mÃ¡scara
                image = Image.open(img_path).convert('RGB')
                gt = Image.open(gt_path).convert('L')

                # Verificar si necesitan resize
                if image.size != gt.size:
                    resized_count += 1
                    target_size = image.size  # Usar tamaÃ±o de la imagen como referencia
                    print(f"   ğŸ“ Redimensionando {os.path.basename(gt_path)}: {gt.size} â†’ {target_size}")

                    # Resize de la mÃ¡scara usando interpolaciÃ³n bicÃºbica
                    gt = gt.resize(target_size, Image.BICUBIC)

                # Convertir a numpy arrays y guardar
                image_np = np.array(image)
                gt_np = np.array(gt)

                self.processed_data.append((image_np, gt_np))

            except Exception as e:
                error_count += 1
                print(f"   âŒ Error procesando {os.path.basename(img_path)}: {str(e)}")

        print(f"\nğŸ“ˆ RESUMEN DEL PREPROCESAMIENTO:")
        print(f"   â€¢ Pares procesados: {len(self.processed_data)}")
        print(f"   â€¢ MÃ¡scaras redimensionadas: {resized_count}")
        print(f"   â€¢ Errores encontrados: {error_count}")
        print(f"   â€¢ âœ… Todas las imÃ¡genes estÃ¡n listas para augmentaciÃ³n")

    def get_transforms(self):
        if self.augmentations:
            print('\nğŸ¨ CONFIGURANDO AUGMENTACIONES AVANZADAS:')
            transform = A.Compose([
                A.Resize(self.trainsize, self.trainsize),
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.5),
                A.RandomRotate90(p=0.5),
                A.ShiftScaleRotate(
                    shift_limit=0.1, 
                    scale_limit=0.1, 
                    rotate_limit=45, 
                    p=0.5, 
                    border_mode=0
                ),
                A.RandomBrightnessContrast(
                    brightness_limit=0.2,
                    contrast_limit=0.2,
                    p=0.5
                ),
                A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),
                A.HueSaturationValue(
                    hue_shift_limit=20,
                    sat_shift_limit=30,
                    val_shift_limit=20,
                    p=0.3
                ),
                A.Normalize(
                    mean=(0.485, 0.456, 0.406),
                    std=(0.229, 0.224, 0.225)
                ),
                ToTensorV2()
            ])

            print('   âœ… Augmentaciones configuradas:')
            print('      - GeomÃ©tricas: Flip H/V (50%), RotaciÃ³n 90Â° (50%), ShiftScaleRotate (50%)')
            print('      - FotomÃ©tricas: Brillo/Contraste (50%), Ruido Gaussiano (30%)')
            print('      - Color: HSV (30%)')
            print('      - NormalizaciÃ³n ImageNet + ToTensor')

            return transform
        else:
            print('\nâ¡ï¸  CONFIGURANDO TRANSFORMACIONES BÃSICAS:')
            transform = A.Compose([
                A.Resize(self.trainsize, self.trainsize),
                A.Normalize(
                    mean=(0.485, 0.456, 0.406),
                    std=(0.229, 0.224, 0.225)
                ),
                ToTensorV2()
            ])
            print('   âœ… Solo resize + normalizaciÃ³n configurados')
            return transform

    def __getitem__(self, index):
        # Obtener datos preprocesados (ya redimensionados una vez)
        image_np, gt_np = self.processed_data[index]

        # Aplicar augmentaciones (si estÃ¡n activadas)
        augmented = self.transform(image=image_np, mask=gt_np)
        image = augmented['image']
        gt = augmented['mask'].unsqueeze(0).float() / 255.0

        return image, gt

    def __len__(self):
        return self.size

def get_loader(image_root, gt_root, batchsize, trainsize, shuffle=True, num_workers=4, pin_memory=True, augmentation=True):
    print(f"\nğŸš€ CREANDO DATALOADER:")
    print(f"   â€¢ Directorio de imÃ¡genes: {image_root}")
    print(f"   â€¢ Directorio de ground truths: {gt_root}")
    print(f"   â€¢ TamaÃ±o de entrenamiento: {trainsize}x{trainsize}")
    print(f"   â€¢ Batch size: {batchsize}")
    print(f"   â€¢ Augmentaciones: {'âœ… Activadas' if augmentation else 'âŒ Desactivadas'}")

    dataset = CODataset(image_root, gt_root, trainsize, augmentation)

    # Calcular informaciÃ³n adicional del entrenamiento
    total_batches = len(dataset) // batchsize
    remaining_samples = len(dataset) % batchsize

    print(f"\nğŸ“ˆ INFORMACIÃ“N DE ENTRENAMIENTO:")
    print(f"   â€¢ Total de imÃ¡genes para entrenamiento: {len(dataset)}")
    print(f"   â€¢ Batches por Ã©poca: {total_batches}")
    if remaining_samples > 0:
        print(f"   â€¢ Muestras en el Ãºltimo batch: {remaining_samples}")

    if augmentation:
        print(f"   â€¢ ğŸ² Variaciones por Ã©poca: INFINITAS (transformaciones aleatorias)")
        print(f"   â€¢ ğŸ”„ Cada Ã©poca verÃ¡ versiones diferentes de las mismas imÃ¡genes")
    else:
        print(f"   â€¢ ğŸ“Š Muestras fijas por Ã©poca: {len(dataset)}")

    data_loader = data.DataLoader(
        dataset=dataset,
        batch_size=batchsize,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=pin_memory
    )
    return data_loader

class test_dataset:
    def __init__(self, image_root, gt_root, testsize):
        self.testsize = testsize
        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg') or f.endswith('.png') or f.endswith('.jpeg') or f.endswith('.JPG')]
        self.gts = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.tif') or f.endswith('.png') or f.endswith('.jpg') or f.endswith('.jpeg') or f.endswith('.JPG')]

        self.images = sorted(self.images)
        self.gts = sorted(self.gts)

        print(f"\nğŸ§ª DATASET DE PRUEBA:")
        print(f"   â€¢ ImÃ¡genes de prueba: {len(self.images)}")
        print(f"   â€¢ Ground truths de prueba: {len(self.gts)}")
        print(f"   â€¢ âš ï¸  NOTA: Las imÃ¡genes de prueba se redimensionan en cada load_data()")

        self.transform = transforms.Compose([
            transforms.Resize((self.testsize, self.testsize)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        self.gt_transform = transforms.ToTensor()
        self.size = len(self.images)
        self.index = 0

    def load_data(self):
        image = self.rgb_loader(self.images[self.index])
        gt = self.binary_loader(self.gts[self.index])

        # Verificar y ajustar tamaÃ±os si es necesario (solo para test)
        if image.size != gt.size:
            gt = gt.resize(image.size, Image.BICUBIC)

        image = self.transform(image).unsqueeze(0)

        name = self.images[self.index].split('/')[-1]
        if name.endswith('.jpg'):
            name = name.split('.jpg')[0] + '.png'
        self.index += 1
        return image, gt, name

    def rgb_loader(self, path):
        with open(path, 'rb') as f:
            img = Image.open(f)
            return img.convert('RGB')

    def binary_loader(self, path):
        with open(path, 'rb') as f:
            img = Image.open(f)
            return img.convert('L')

    def __len__(self):
        return self.size

# FunciÃ³n para mostrar resumen completo del dataset
def show_dataset_summary(train_loader, test_dataset=None):
    """
    Muestra un resumen completo del dataset con informaciÃ³n de augmentaciones
    """
    print(f"\n" + "="*70)
    print(f"ğŸ“‹ RESUMEN COMPLETO DEL DATASET")
    print(f"="*70)

    # InformaciÃ³n del dataset de entrenamiento
    train_dataset = train_loader.dataset
    print(f"ğŸ‹ï¸  ENTRENAMIENTO:")
    print(f"   â€¢ ImÃ¡genes base: {len(train_dataset)}")
    print(f"   â€¢ Batch size: {train_loader.batch_size}")
    print(f"   â€¢ Batches por Ã©poca: {len(train_loader)}")
    print(f"   â€¢ Preprocesamiento: âœ… Una sola vez al inicializar")

    if train_dataset.augmentations:
        print(f"   â€¢ Augmentaciones: âœ… ACTIVADAS")
        print(f"     - Cada imagen se transforma aleatoriamente")
        print(f"     - Variaciones por Ã©poca: INFINITAS")
        print(f"     - Diversidad: Muy alta")
    else:
        print(f"   â€¢ Augmentaciones: âŒ DESACTIVADAS")
        print(f"     - ImÃ¡genes fijas por Ã©poca: {len(train_dataset)}")
        print(f"     - Diversidad: Limitada")

    if test_dataset:
        print(f"\nğŸ§ª PRUEBA:")
        print(f"   â€¢ ImÃ¡genes de prueba: {len(test_dataset)}")
        print(f"   â€¢ Augmentaciones: âŒ Desactivadas (solo resize)")

    print(f"\nğŸ’¾ CONFIGURACIÃ“N:")
    print(f"   â€¢ TamaÃ±o de imagen: {train_dataset.trainsize}x{train_dataset.trainsize}")
    print(f"   â€¢ Shuffle: {'âœ…' if train_loader.sampler is None else 'âŒ'}")
    print(f"   â€¢ Num workers: {train_loader.num_workers}")
    print(f"   â€¢ Pin memory: {'âœ…' if train_loader.pin_memory else 'âŒ'}")
    print(f"="*70)

# FunciÃ³n para demostrar el efecto de las augmentaciones
def demonstrate_augmentations(dataset, num_samples=3):
    """
    Demuestra cÃ³mo las augmentaciones crean diferentes versiones de la misma imagen
    """
    if not dataset.augmentations:
        print("âŒ Las augmentaciones estÃ¡n desactivadas")
        return

    print(f"\nğŸ¨ DEMOSTRACIÃ“N DE AUGMENTACIONES:")
    print(f"Mostrando {num_samples} transformaciones de la primera imagen...")

    for i in range(num_samples):
        image, gt = dataset[0]  # Siempre la misma imagen base
        print(f"   Muestra {i+1}: Tensor shape {image.shape}, GT shape {gt.shape}")
        print(f"   - Valores Ãºnicos en imagen: {len(torch.unique(image))}")
        print(f"   - Min/Max imagen: {image.min():.3f}/{image.max():.3f}")

    print("âœ… Cada llamada produce una transformaciÃ³n diferente!")

def verify_dataset_integrity(image_root, gt_root):
    """
    Verifica la integridad del dataset antes del preprocesamiento
    """
    print(f"\nğŸ” VERIFICANDO INTEGRIDAD DEL DATASET...")

    images = sorted([f for f in os.listdir(image_root) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])
    gts = sorted([f for f in os.listdir(gt_root) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])

    size_stats = {}
    mismatches = 0

    for img_name, gt_name in zip(images, gts):
        try:
            img = Image.open(os.path.join(image_root, img_name))
            gt = Image.open(os.path.join(gt_root, gt_name))

            img_size = img.size
            gt_size = gt.size

            if img_size != gt_size:
                mismatches += 1

            # EstadÃ­sticas de tamaÃ±os
            if img_size not in size_stats:
                size_stats[img_size] = 0
            size_stats[img_size] += 1

        except Exception as e:
            print(f"   âŒ Error con {img_name}: {e}")

    print(f"\nğŸ“Š ESTADÃSTICAS DE TAMAÃ‘OS:")
    for size, count in sorted(size_stats.items(), key=lambda x: x[1], reverse=True):
        print(f"   â€¢ {size}: {count} imÃ¡genes")

    print(f"\nğŸ“ˆ RESUMEN:")
    print(f"   â€¢ Total de pares: {len(images)}")
    print(f"   â€¢ Pares con tamaÃ±os diferentes: {mismatches}")
    print(f"   â€¢ ğŸ”§ Se redimensionarÃ¡n {mismatches} mÃ¡scaras UNA SOLA VEZ")

    return len(images), mismatches
